{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Install dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install PyTorch\n",
    "# https://download.pytorch.org/whl/lts/1.8/torch_lts.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in ./env/lib/python3.8/site-packages (4.21.0.dev0)\n",
      "Requirement already satisfied: numpy>=1.17 in ./env/lib/python3.8/site-packages (from transformers) (1.23.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in ./env/lib/python3.8/site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in ./env/lib/python3.8/site-packages (from transformers) (4.64.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in ./env/lib/python3.8/site-packages (from transformers) (0.8.1)\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in ./env/lib/python3.8/site-packages (from transformers) (0.12.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in ./env/lib/python3.8/site-packages (from transformers) (2022.7.9)\n",
      "Requirement already satisfied: requests in ./env/lib/python3.8/site-packages (from transformers) (2.28.1)\n",
      "Requirement already satisfied: packaging>=20.0 in ./env/lib/python3.8/site-packages (from transformers) (21.3)\n",
      "Requirement already satisfied: filelock in ./env/lib/python3.8/site-packages (from transformers) (3.7.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in ./env/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.3.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in ./env/lib/python3.8/site-packages (from packaging>=20.0->transformers) (3.0.9)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in ./env/lib/python3.8/site-packages (from requests->transformers) (2.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./env/lib/python3.8/site-packages (from requests->transformers) (3.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./env/lib/python3.8/site-packages (from requests->transformers) (2022.6.15)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in ./env/lib/python3.8/site-packages (from requests->transformers) (1.26.10)\n"
     ]
    }
   ],
   "source": [
    "# Install transformers\n",
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import and Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing dependencies from transformers\n",
    "from transformers import PegasusForConditionalGeneration, PegasusTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentencepiece in ./env/lib/python3.8/site-packages (0.1.96)\r\n"
     ]
    }
   ],
   "source": [
    "!pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load tokenizer \n",
    "tokenizer = PegasusTokenizer.from_pretrained(\"google/pegasus-xsum\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model \n",
    "model = PegasusForConditionalGeneration.from_pretrained(\"google/pegasus-xsum\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Perform Abstractive Summarization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "The X-ray, taken ahead of a forthcoming exhibition, did not catch much of the peasant woman. Instead, it picked up on the “lead white, the much heavier pigment he used for his face,” Stevenson adds.\n",
    "\n",
    "Van Gogh reused canvases on many occasions to save money, typically opting to paint on the back side of a canvas rather than paint over an existing work. The self-portrait was most likely lost after Jo Bonger, his sister-in-law, lent the canvas to an exhibition in Amsterdam in 1905. Curators at that exhibition probably deemed the self-portrait as less complete, choosing to glue cardboard to the portrait side in order to secure the canvas before framing, per the statement.\n",
    "\n",
    "The work is likely part of a series of experimental self-portraits van Gogh made in the summer of 1887, a few years after he painted the peasant lady, according to the museum. Five other self-portraits he painted in Nuen—the Dutch town he lived in for two years—on the backs of earlier works are on display at the Van Gogh Museum in the Netherlands.\n",
    "\n",
    "Thanks to a specially made lightbox, an X-ray of the self-portrait will be on view at the museum’s coming exhibition, “A Taste for Impressionism.”\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create tokens - number representation of our text\n",
    "tokens = tokenizer(text, truncation=True, padding=\"longest\", return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  139,  1346,   121,  5654,   108,   784,  1573,   113,   114, 12480,\n",
       "          3388,   108,   368,   146,  2602,   249,   113,   109, 52422,  1590,\n",
       "           107,  3054,   108,   126,  3093,   164,   124,   109,   185, 21248,\n",
       "           695,   108,   109,   249, 11959, 20362,   178,   263,   118,   169,\n",
       "           749,   483, 30934,  3488,   107,  4247, 38622, 28495, 41892,   124,\n",
       "           223,  5430,   112,   803,   408,   108,  2222, 18208,   112,  1999,\n",
       "           124,   109,   247,   477,   113,   114,  5999,   880,   197,  1999,\n",
       "           204,   142,  1385,   201,   107,   139,   813,   121, 46832,   140,\n",
       "           205,   770,  1166,   244,  6513, 48662,   420,   108,   169,  3051,\n",
       "           121,   386,   121,  5505,   108, 28352,   109,  5999,   112,   142,\n",
       "          3388,   115,  9171,   115, 28613,   107, 42825,   116,   134,   120,\n",
       "          3388,   864,  7595,   109,   813,   121, 46832,   130,   478,   573,\n",
       "           108,  2832,   112,  7156, 11543,   112,   109,  8130,   477,   115,\n",
       "           385,   112,  1612,   109,  5999,   269, 13676,   108,   446,   109,\n",
       "          1736,   107,   139,   201,   117,   770,   297,   113,   114,   679,\n",
       "           113,  7707,   813,   121, 46832,   116,  4406, 38622,   266,   115,\n",
       "           109,   922,   113, 40724,   108,   114,   324,   231,   244,   178,\n",
       "          4207,   109, 52422,  5333,   108,   992,   112,   109,  3759,   107,\n",
       "          6418,   176,   813,   121, 46832,   116,   178,  4207,   115,  9182,\n",
       "          1227,   560,   544,  6015,  1120,   178,  2703,   115,   118,   228,\n",
       "           231,   560,   661,   109,   247,   116,   113,  1678,   659,   127,\n",
       "           124,  1381,   134,   109,  4247, 38622,  2447,   115,   109,  6508,\n",
       "           107,  1633,   112,   114,  6191,   266,   523,  4835,   108,   142,\n",
       "          1346,   121,  5654,   113,   109,   813,   121, 46832,   138,   129,\n",
       "           124,   700,   134,   109,  3759,   123,   116,   792,  3388,   108,\n",
       "           185,   251, 15453,   118, 92735,  1181,     1]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input tokens\n",
    "tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summarize \n",
    "summary = model.generate(**tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  139,  1346,   121,  5654,   108,   784,  1573,   113,   114, 12480,\n",
       "           3388,   108,   368,   146,  2602,   249,   113,   109, 52422,  1590,\n",
       "            107,  3054,   108,   126,  3093,   164,   124,   109,   185, 21248,\n",
       "            695,   108,   109,   249, 11959, 20362,   178,   263,   118,   169,\n",
       "            749,   483, 30934,  3488,   107,  4247, 38622, 28495, 41892,   124,\n",
       "            223,  5430,   112,   803,   408,   108,  2222, 18208,   112,  1999,\n",
       "            124,   109,   247,   477,   113,   114,  5999,   880,   197,  1999,\n",
       "            204,   142,  1385,   201,   107,   139,   813,   121, 46832,   140,\n",
       "            205,   770,  1166,   244,  6513, 48662,   420,   108,   169,  3051,\n",
       "            121,   386,   121,  5505,   108, 28352,   109,  5999,   112,   142,\n",
       "           3388,   115,  9171,   115, 28613,   107, 42825,   116,   134,   120,\n",
       "           3388,   864,  7595,   109,   813,   121, 46832,   130,   478,   573,\n",
       "            108,  2832,   112,  7156, 11543,   112,   109,  8130,   477,   115,\n",
       "            385,   112,  1612,   109,  5999,   269, 13676,   108,   446,   109,\n",
       "           1736,   107,   139,   201,   117,   770,   297,   113,   114,   679,\n",
       "            113,  7707,   813,   121, 46832,   116,  4406, 38622,   266,   115,\n",
       "            109,   922,   113, 40724,   108,   114,   324,   231,   244,   178,\n",
       "           4207,   109, 52422,  5333,   108,   992,   112,   109,  3759,   107,\n",
       "           6418,   176,   813,   121, 46832,   116,   178,  4207,   115,  9182,\n",
       "           1227,   560,   544,  6015,  1120,   178,  2703,   115,   118,   228,\n",
       "            231,   560,   661,   109,   247,   116,   113,  1678,   659,   127,\n",
       "            124,  1381,   134,   109,  4247, 38622,  2447,   115,   109,  6508,\n",
       "            107,  1633,   112,   114,  6191,   266,   523,  4835,   108,   142,\n",
       "           1346,   121,  5654,   113,   109,   813,   121, 46832,   138,   129,\n",
       "            124,   700,   134,   109,  3759,   123,   116,   792,  3388,   108,\n",
       "            185,   251, 15453,   118, 92735,  1181,     1]]),\n",
       " 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "          1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{**tokens}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    0,   202,   813,   121, 46832,  4207,   141, 12389,  4406, 38622,\n",
       "           154,   197,   114,  1902,   754,   148,   174,  3087,   141,   142,\n",
       "          1346,   121,  5654,   108,   992,   112,   109,  4247, 38622,  2447,\n",
       "           115,  9171,   107,     1]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# summary in tokens\n",
    "summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([    0,   202,   813,   121, 46832,  4207,   141, 12389,  4406, 38622,\n",
       "          154,   197,   114,  1902,   754,   148,   174,  3087,   141,   142,\n",
       "         1346,   121,  5654,   108,   992,   112,   109,  4247, 38622,  2447,\n",
       "          115,  9171,   107,     1])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Output summary tokens\n",
    "summary[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A self-portrait painted by Vincent van Gogh more than a century ago has been identified by an X-ray, according to the Van Gogh Museum in Amsterdam.'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Decode summary\n",
    "tokenizer.decode(summary[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a pickle file\n",
    "import pickle\n",
    "pickle_out = open('summarizer.pkl','wb')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
